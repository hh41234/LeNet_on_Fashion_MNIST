{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dataset import get_data, normalize\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import scipy.spatial.distance as distance\n",
    "\n",
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_covariance_matrix(X):\n",
    "    mean_vec = np.mean(X, axis=0)\n",
    "    center_mat = X - mean_vec\n",
    "    cov = np.dot(center_mat.T, center_mat) / (X.shape[0] - 1)\n",
    "    return cov\n",
    "\n",
    "\n",
    "def compute_eigenvalues_eigenvectors(cov):\n",
    "    eig_val, eig_vec = np.linalg.eig(cov)\n",
    "    idx = np.argsort(eig_val)[::-1]\n",
    "    sort_eig_val = eig_val[idx]\n",
    "    sort_eig_vec = eig_vec[:, idx]\n",
    "    return sort_eig_val, sort_eig_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_features_pca_1(features, labels, cnt):\n",
    "    cov = compute_covariance_matrix(features)\n",
    "    eig_val, eig_vec = compute_eigenvalues_eigenvectors(cov)\n",
    "    data = np.dot(features, eig_vec[:, :2])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        idx = labels == label\n",
    "        plt.scatter(data[idx, 0], data[idx, 1], c=colors(i), label=str(label))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('Visualization of Conv2 layer using PCA')\n",
    "    path = \"./pca_conv2/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(\"./pca_conv2/\" + str(cnt) + \".png\")\n",
    "    plt.show()\n",
    "def visualize_features_pca_2(features, labels, cnt):\n",
    "    cov = compute_covariance_matrix(features)\n",
    "    eig_val, eig_vec = compute_eigenvalues_eigenvectors(cov)\n",
    "    data = np.dot(features, eig_vec[:, :2])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        idx = labels == label\n",
    "        plt.scatter(data[idx, 0], data[idx, 1], c=colors(i), label=str(label))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('Visualization of fc1 layer using PCA')\n",
    "    path = \"./pca_fc1/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(\"./pca_fc1/\" + str(cnt) + \".png\")\n",
    "    plt.show()\n",
    "def visualize_features_pca_3(features, labels, cnt):\n",
    "    cov = compute_covariance_matrix(features)\n",
    "    eig_val, eig_vec = compute_eigenvalues_eigenvectors(cov)\n",
    "    data = np.dot(features, eig_vec[:, :2])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        idx = labels == label\n",
    "        plt.scatter(data[idx, 0], data[idx, 1], c=colors(i), label=str(label))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('Visualization of the last layer using PCA')\n",
    "    path = \"./pca_final/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(\"./pca_final/\" + str(cnt) + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_perplexity(dist, idx, beta):\n",
    "    prob = np.exp(-dist * beta)\n",
    "    prob[idx] = 0\n",
    "    sum_prob = np.sum(prob)\n",
    "    if sum_prob == 0:\n",
    "        prob = np.maximum(prob, 1e-12)\n",
    "        perp = -12\n",
    "    else:\n",
    "        prob /= sum_prob\n",
    "        perp = 0\n",
    "        for pj in prob:\n",
    "            if pj != 0:\n",
    "                perp += -pj * np.log(pj)\n",
    "    return perp, prob\n",
    "\n",
    "\n",
    "def compute_prob(x, perplexity=30.0):\n",
    "    (n, d) = x.shape\n",
    "    sum_x = np.sum(np.square(x), 1)\n",
    "    dist = np.add(np.add(-2 * np.dot(x, x.T), sum_x).T, sum_x)\n",
    "    pair_prob = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    base_perp = np.log(perplexity)\n",
    "\n",
    "    for i in range(n):\n",
    "        mn = -np.inf\n",
    "        mx = np.inf\n",
    "        perp, this_prob = compute_perplexity(dist[i], i, beta[i])\n",
    "        perp_diff = perp - base_perp\n",
    "        tries = 0\n",
    "        while np.abs(perp_diff) > 1e-5 and tries < 50:\n",
    "            if perp_diff > 0:\n",
    "                mn = beta[i].copy()\n",
    "                if mx == np.inf or mx == -np.inf:\n",
    "                    beta[i] = beta[i] * 2\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + mx) / 2\n",
    "            else:\n",
    "                mx = beta[i].copy()\n",
    "                if mn == np.inf or mn == -np.inf:\n",
    "                    beta[i] = beta[i] / 2\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + mn) / 2\n",
    "\n",
    "            perp, this_prob = compute_perplexity(dist[i], i, beta[i])\n",
    "            perp_diff = perp - base_perp\n",
    "            tries = tries + 1\n",
    "        pair_prob[i,] = this_prob\n",
    "    return pair_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tsne(X, n_components=2, perplexity=30.0, num_iter=500, lr=300):\n",
    "    (n, d) = X.shape\n",
    "    y = np.random.randn(n, n_components)\n",
    "    dy = np.zeros((n, n_components))\n",
    "    p1 = compute_prob(X, perplexity)\n",
    "    p1 = ((p1 + np.transpose(p1)) / np.sum(p1)) * 4\n",
    "    p1 = np.maximum(p1, 1e-12)\n",
    "\n",
    "    for iter in range(num_iter):\n",
    "        sum_y = np.sum(np.square(y), 1)\n",
    "        num = 1 / (1 + np.add(np.add(-2 * np.dot(y, y.T), sum_y).T, sum_y))\n",
    "        for i in range(n):\n",
    "            num[i, i] = 0\n",
    "        p2 = np.maximum(num / np.sum(num), 1e-12)\n",
    "        l = p1 - p2\n",
    "        for i in range(n):\n",
    "            dy[i, :] = np.sum(np.tile(l[:, i] * num[:, i], (n_components, 1)).T * (y[i, :] - y), 0)\n",
    "        y = y - lr * dy - np.tile(np.mean(y, 0), (n, 1))\n",
    "        if iter == 100:\n",
    "            p1 = p1 / 4\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_features_tsne_1(features, labels, cnt):\n",
    "    #print(\"begin\")\n",
    "    Y = tsne(features)\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], 20, labels, cmap=\"tab10\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('Visualization of conv2 layer using t-SNE')\n",
    "    path = \"./tsne_conv2/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(\"./tsne_conv2/\" + str(cnt) + \".png\")\n",
    "    plt.show()\n",
    "def visualize_features_tsne_2(features, labels, cnt):\n",
    "    Y = tsne(features)\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], 20, labels, cmap=\"tab10\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('Visualization of fc1 layer using t-SNE')\n",
    "    path = \"./tsne_fc1/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(\"./tsne_fc1/\" + str(cnt) + \".png\")\n",
    "    plt.show()\n",
    "def visualize_features_tsne_3(features, labels, cnt):\n",
    "    Y = tsne(features)\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], 20, labels, cmap=\"tab10\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('Visualization of the last layer using t-SNE')\n",
    "    path = \"./tsne_final/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(\"./tsne_final/\" + str(cnt) + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_features_1(features, labels):\n",
    "    visualize_features_tsne_1(features, labels, cnt)\n",
    "    visualize_features_pca_1(features,labels, cnt)\n",
    "def visualize_features_2(features, labels):\n",
    "    visualize_features_tsne_2(features, labels, cnt)\n",
    "    visualize_features_pca_2(features,labels, cnt)\n",
    "def visualize_features_3(features, labels):\n",
    "    visualize_features_tsne_3(features, labels, cnt)\n",
    "    visualize_features_pca_3(features,labels, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ######################## Get train/test dataset ########################\n",
    "    X_train, X_test, Y_train, Y_test = get_data('dataset')\n",
    "    ########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).long())\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).long())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    class LeNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LeNet, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "            self.pool1 = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "            self.pool2 = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3= nn.Linear(84, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool1(F.relu(self.conv1(x)))\n",
    "            x = self.pool2(F.relu(self.conv2(x)))\n",
    "            con2 = x\n",
    "            x = x.view(-1, 16 * 5 * 5)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            fc1 = x\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return con2, fc1, x\n",
    "\n",
    "    class MyNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MyNet, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.pool1 = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "            self.pool2 = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(64 * 5 * 5, 512)\n",
    "            self.fc2 = nn.Linear(512, 256)\n",
    "            self.fc3= nn.Linear(256, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool1(self.bn1(F.relu(self.conv1(x))))\n",
    "            x = self.pool2(self.bn2(F.relu(self.conv2(x))))\n",
    "            con2 = x\n",
    "            x = x.view(-1, 64 * 5 * 5)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            fc1 = x\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return con2, fc1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Train Loss: 2.1627, Train Acc: 0.338, Test Loss: 2.2589, Test Acc: 0.260\n",
      "Epoch [2/150], Train Loss: 2.1915, Train Acc: 0.419, Test Loss: 2.0883, Test Acc: 0.469\n",
      "Epoch [3/150], Train Loss: 1.8943, Train Acc: 0.476, Test Loss: 1.6261, Test Acc: 0.414\n",
      "Epoch [4/150], Train Loss: 1.3428, Train Acc: 0.516, Test Loss: 1.1154, Test Acc: 0.581\n",
      "Epoch [5/150], Train Loss: 1.0673, Train Acc: 0.583, Test Loss: 1.0206, Test Acc: 0.616\n",
      "Epoch [6/150], Train Loss: 0.9649, Train Acc: 0.637, Test Loss: 0.9108, Test Acc: 0.643\n",
      "Epoch [7/150], Train Loss: 0.8923, Train Acc: 0.659, Test Loss: 0.8451, Test Acc: 0.685\n",
      "Epoch [8/150], Train Loss: 0.8180, Train Acc: 0.697, Test Loss: 0.7975, Test Acc: 0.712\n",
      "Epoch [9/150], Train Loss: 0.8283, Train Acc: 0.694, Test Loss: 0.8572, Test Acc: 0.686\n",
      "Epoch [10/150], Train Loss: 0.7615, Train Acc: 0.732, Test Loss: 0.8100, Test Acc: 0.708\n",
      "Epoch [11/150], Train Loss: 0.7141, Train Acc: 0.733, Test Loss: 0.7278, Test Acc: 0.736\n",
      "Epoch [12/150], Train Loss: 0.6969, Train Acc: 0.735, Test Loss: 0.7149, Test Acc: 0.725\n",
      "Epoch [13/150], Train Loss: 0.6747, Train Acc: 0.748, Test Loss: 0.8407, Test Acc: 0.700\n",
      "Epoch [14/150], Train Loss: 0.7255, Train Acc: 0.715, Test Loss: 0.7162, Test Acc: 0.721\n",
      "Epoch [15/150], Train Loss: 0.6813, Train Acc: 0.745, Test Loss: 0.7910, Test Acc: 0.685\n",
      "Epoch [16/150], Train Loss: 0.6856, Train Acc: 0.737, Test Loss: 0.7474, Test Acc: 0.705\n",
      "Epoch [17/150], Train Loss: 0.6306, Train Acc: 0.745, Test Loss: 0.7024, Test Acc: 0.737\n",
      "Epoch [18/150], Train Loss: 0.5989, Train Acc: 0.772, Test Loss: 0.6605, Test Acc: 0.757\n",
      "Epoch [19/150], Train Loss: 0.6048, Train Acc: 0.766, Test Loss: 0.6728, Test Acc: 0.751\n",
      "Epoch [20/150], Train Loss: 0.5689, Train Acc: 0.787, Test Loss: 0.6300, Test Acc: 0.767\n",
      "Epoch [21/150], Train Loss: 0.5972, Train Acc: 0.764, Test Loss: 0.6563, Test Acc: 0.751\n",
      "Epoch [22/150], Train Loss: 0.5624, Train Acc: 0.778, Test Loss: 0.6867, Test Acc: 0.744\n",
      "Epoch [23/150], Train Loss: 0.5457, Train Acc: 0.793, Test Loss: 0.6078, Test Acc: 0.770\n",
      "Epoch [24/150], Train Loss: 0.5293, Train Acc: 0.806, Test Loss: 0.6624, Test Acc: 0.755\n",
      "Epoch [25/150], Train Loss: 0.5114, Train Acc: 0.806, Test Loss: 0.6496, Test Acc: 0.768\n",
      "Epoch [26/150], Train Loss: 0.5104, Train Acc: 0.803, Test Loss: 0.6259, Test Acc: 0.768\n",
      "Epoch [27/150], Train Loss: 0.5189, Train Acc: 0.804, Test Loss: 0.6827, Test Acc: 0.757\n",
      "Epoch [28/150], Train Loss: 0.5553, Train Acc: 0.797, Test Loss: 0.6396, Test Acc: 0.764\n",
      "Epoch [29/150], Train Loss: 0.4855, Train Acc: 0.803, Test Loss: 0.5797, Test Acc: 0.776\n",
      "Epoch [30/150], Train Loss: 0.4496, Train Acc: 0.831, Test Loss: 0.5644, Test Acc: 0.799\n",
      "Epoch [31/150], Train Loss: 0.4307, Train Acc: 0.844, Test Loss: 0.5803, Test Acc: 0.770\n",
      "Epoch [32/150], Train Loss: 0.4251, Train Acc: 0.842, Test Loss: 0.5966, Test Acc: 0.767\n",
      "Epoch [33/150], Train Loss: 0.4347, Train Acc: 0.837, Test Loss: 0.5633, Test Acc: 0.782\n",
      "Epoch [34/150], Train Loss: 0.4085, Train Acc: 0.845, Test Loss: 0.5610, Test Acc: 0.802\n",
      "Epoch [35/150], Train Loss: 0.4049, Train Acc: 0.846, Test Loss: 0.5934, Test Acc: 0.793\n",
      "Epoch [36/150], Train Loss: 0.4072, Train Acc: 0.842, Test Loss: 0.6280, Test Acc: 0.775\n",
      "Epoch [37/150], Train Loss: 0.3866, Train Acc: 0.850, Test Loss: 0.5917, Test Acc: 0.780\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m outputs \u001B[38;5;241m=\u001B[39m net(inputs)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m---> 22\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     25\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mf:\\python\\venv\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mf:\\python\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = MyNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.0025, momentum=0.9)\n",
    "\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    loss_test_list = []\n",
    "    acc_test_list = []\n",
    "    num_epoch = 150\n",
    "    for epoch in range(num_epoch):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)[-1]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        acc_list.append(train_acc)\n",
    "        loss_list.append(train_loss)\n",
    "        net.eval()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        testing_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)[-1]\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                testing_loss += loss.item()\n",
    "        test_loss = testing_loss / len(test_loader)\n",
    "        test_acc = correct / total\n",
    "        acc_test_list.append(test_acc)\n",
    "        loss_test_list.append(test_loss)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.3f}, Test Loss: {:.4f}, Test Acc: {:.3f}'\n",
    "          .format(epoch+1, num_epoch, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "        path = \"./loss/\"\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        plt.plot(loss_list, label='Train Loss')\n",
    "        plt.plot(loss_test_list, label='Test Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(\"./loss/\" + \"loss_MyNet.png\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(acc_list, label='Train Accuracy')\n",
    "        plt.plot(acc_test_list, label='Test Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.savefig(\"./loss/\" + \"Acccuracy_MyNet.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    net.eval()\n",
    "    loss_test_list = []\n",
    "    acc_test_list = []\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        features_list_con2 = []\n",
    "        features_list_fc1 = []\n",
    "        features_list_final = []\n",
    "        labels_list = []\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            con2, fc1, final = net(inputs)\n",
    "            features_con2 = con2.reshape(con2.shape[0], -1)\n",
    "            features_fc1 = fc1.reshape(fc1.shape[0], -1)\n",
    "            features_final = final.reshape(final.shape[0], -1)\n",
    "            features_np_1 = features_con2.cpu().numpy()\n",
    "            features_np_2 = features_fc1.cpu().numpy()\n",
    "            features_np_3 = features_final.cpu().numpy()\n",
    "            features_list_con2.append(features_np_1)\n",
    "            features_list_fc1.append(features_np_2)\n",
    "            features_list_final.append(features_np_3)\n",
    "            labels_list.append(labels.cpu().numpy())\n",
    "        #\n",
    "        #     outputs = net(inputs)[-1]\n",
    "        #     _, predicted = torch.max(outputs.data, 1)\n",
    "        #     total += labels.size(0)\n",
    "        #     correct += (predicted == labels).sum().item()\n",
    "        #     running_loss += loss.item()\n",
    "        #\n",
    "        # print(f'ecoch {epoch+1}, loss {running_loss / len(train_loader):.3f}, train acc {correct / total:.3f}')\n",
    "        # acc_list.append(correct / total)\n",
    "        # loss_list.append(running_loss / len(train_loader))\n",
    "        # acc = correct / total\n",
    "        # print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    features_arr_1 = np.concatenate(features_list_con2, axis=0)\n",
    "    features_arr_2 = np.concatenate(features_list_fc1, axis=0)\n",
    "    features_arr_3 = np.concatenate(features_list_final, axis=0)\n",
    "    labels_arr = np.concatenate(labels_list, axis=0)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    visualize_features_1(features_arr_1, labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    visualize_features_2(features_arr_2, labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    visualize_features_3(features_arr_3, labels_arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}